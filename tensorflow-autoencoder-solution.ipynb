{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-06T07:20:25.590693Z","iopub.execute_input":"2022-06-06T07:20:25.591094Z","iopub.status.idle":"2022-06-06T07:20:25.600421Z","shell.execute_reply.started":"2022-06-06T07:20:25.591059Z","shell.execute_reply":"2022-06-06T07:20:25.599376Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"/kaggle/input/tabular-playground-series-jun-2022/sample_submission.csv\n/kaggle/input/tabular-playground-series-jun-2022/data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras","metadata":{"execution":{"iopub.status.busy":"2022-06-06T07:20:25.607930Z","iopub.execute_input":"2022-06-06T07:20:25.608347Z","iopub.status.idle":"2022-06-06T07:20:25.616120Z","shell.execute_reply.started":"2022-06-06T07:20:25.608312Z","shell.execute_reply":"2022-06-06T07:20:25.614369Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"df_raw = pd.read_csv('../input/tabular-playground-series-jun-2022/data.csv', index_col=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T07:20:25.618997Z","iopub.execute_input":"2022-06-06T07:20:25.619695Z","iopub.status.idle":"2022-06-06T07:20:39.189884Z","shell.execute_reply.started":"2022-06-06T07:20:25.619658Z","shell.execute_reply":"2022-06-06T07:20:39.188874Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"for col in df_raw:\n    if df_raw[col].dtype == 'float64':\n        df_raw[col] = df_raw[col].astype('float32')\n    else: # There is int 64\n        df_raw[col] = df_raw[col].astype('int32')","metadata":{"execution":{"iopub.status.busy":"2022-06-06T07:20:39.191268Z","iopub.execute_input":"2022-06-06T07:20:39.192195Z","iopub.status.idle":"2022-06-06T07:20:43.859858Z","shell.execute_reply.started":"2022-06-06T07:20:39.192145Z","shell.execute_reply":"2022-06-06T07:20:43.858784Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"nan_mask = df_raw.isna().astype('int32')\n# df_raw.fillna(-666)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T07:20:43.861552Z","iopub.execute_input":"2022-06-06T07:20:43.862401Z","iopub.status.idle":"2022-06-06T07:20:44.125363Z","shell.execute_reply.started":"2022-06-06T07:20:43.862345Z","shell.execute_reply":"2022-06-06T07:20:44.124455Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, mask_train, mask_test = train_test_split(df_raw, nan_mask, test_size=.1, random_state=42)\nx_train","metadata":{"execution":{"iopub.status.busy":"2022-06-06T07:20:44.126307Z","iopub.execute_input":"2022-06-06T07:20:44.126647Z","iopub.status.idle":"2022-06-06T07:20:45.810564Z","shell.execute_reply.started":"2022-06-06T07:20:44.126617Z","shell.execute_reply":"2022-06-06T07:20:45.809560Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"           F_1_0     F_1_1     F_1_2     F_1_3     F_1_4     F_1_5     F_1_6  \\\nrow_id                                                                         \n378046 -1.490798 -0.720562 -0.913358       NaN  0.675822 -0.068926 -0.256740   \n510062       NaN  0.248052  0.009841  0.010724 -0.805532 -0.014599  1.021628   \n534815 -1.035620  0.587509 -1.709698 -1.040852  0.947988  0.586136 -1.364958   \n342590  0.260022  1.857708       NaN -0.050537 -0.253518 -0.591818 -0.134732   \n559414 -0.070327  0.211908 -1.751384 -1.461679 -1.290441  1.525672 -0.437284   \n...          ...       ...       ...       ...       ...       ...       ...   \n259178  1.218796       NaN  0.267737  0.774914 -1.568090 -0.727271 -0.050377   \n365838  0.741771  0.566133 -0.015954 -1.099916  0.742518 -1.109014  0.628161   \n131932 -1.266722  0.024304 -1.112762 -0.068065 -0.397668  0.739804  0.623387   \n671155 -0.575121  0.014076 -1.933780  0.863119 -1.222825  0.863869 -0.464296   \n121958  0.233272  0.503249  0.252610 -0.194540  2.045176  0.613187  0.294033   \n\n           F_1_7     F_1_8     F_1_9  ...     F_4_5     F_4_6     F_4_7  \\\nrow_id                                ...                                 \n378046  0.915416 -1.416972  0.162724  ...  2.267226  0.294164  0.657129   \n510062  1.489092 -0.361747 -1.233647  ... -0.772674  0.130366  2.494628   \n534815       NaN -0.242823  1.099015  ... -1.139737 -0.900421  0.544825   \n342590  0.407089  0.123022  0.778944  ... -1.181412  2.432050 -1.053403   \n559414  0.144728  0.700818  0.694507  ... -0.112494 -2.676754 -0.060217   \n...          ...       ...       ...  ...       ...       ...       ...   \n259178 -0.014268  1.754509 -1.515554  ... -2.818447 -0.666565  1.312525   \n365838  0.216517  0.127800  0.163856  ...  1.847194 -1.782025  1.049517   \n131932  0.264382 -0.661810 -0.499827  ...  1.892844 -1.560886  0.372720   \n671155  1.049259  1.380140 -0.046534  ...  0.249582  1.081619 -3.197704   \n121958 -0.566269 -1.870568  0.534392  ...  4.169731 -1.394576 -1.150761   \n\n           F_4_8     F_4_9    F_4_10    F_4_11    F_4_12    F_4_13    F_4_14  \nrow_id                                                                        \n378046 -1.623652  1.427957  0.555431  4.764529  0.434515  2.456691  0.367709  \n510062  0.868327  0.411586 -0.287139  1.632814  2.557848 -0.216548  0.534780  \n534815  0.738696 -0.675178 -0.490468 -1.083962  2.272816 -0.535574  0.621225  \n342590  0.985205 -0.903371  1.016687 -3.691421  0.837269  3.431231  0.648106  \n559414 -0.468202  0.383181  0.899809       NaN  3.984332 -0.377657       NaN  \n...          ...       ...       ...       ...       ...       ...       ...  \n259178 -0.076391 -0.493262  0.182865  3.726244  0.651348 -0.308762  1.018395  \n365838  0.106738 -0.952896  0.327642  1.275427  2.628004  0.224034  0.503405  \n131932 -0.764522  0.614927  0.875461 -5.531109  6.277756 -2.384959  0.099292  \n671155  0.666860 -0.705164  0.543630 -5.280212 -0.053185 -0.108882 -0.344734  \n121958       NaN -1.660472 -0.930751  0.381797  0.669120 -0.079348 -0.149050  \n\n[900000 rows x 80 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>F_1_0</th>\n      <th>F_1_1</th>\n      <th>F_1_2</th>\n      <th>F_1_3</th>\n      <th>F_1_4</th>\n      <th>F_1_5</th>\n      <th>F_1_6</th>\n      <th>F_1_7</th>\n      <th>F_1_8</th>\n      <th>F_1_9</th>\n      <th>...</th>\n      <th>F_4_5</th>\n      <th>F_4_6</th>\n      <th>F_4_7</th>\n      <th>F_4_8</th>\n      <th>F_4_9</th>\n      <th>F_4_10</th>\n      <th>F_4_11</th>\n      <th>F_4_12</th>\n      <th>F_4_13</th>\n      <th>F_4_14</th>\n    </tr>\n    <tr>\n      <th>row_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>378046</th>\n      <td>-1.490798</td>\n      <td>-0.720562</td>\n      <td>-0.913358</td>\n      <td>NaN</td>\n      <td>0.675822</td>\n      <td>-0.068926</td>\n      <td>-0.256740</td>\n      <td>0.915416</td>\n      <td>-1.416972</td>\n      <td>0.162724</td>\n      <td>...</td>\n      <td>2.267226</td>\n      <td>0.294164</td>\n      <td>0.657129</td>\n      <td>-1.623652</td>\n      <td>1.427957</td>\n      <td>0.555431</td>\n      <td>4.764529</td>\n      <td>0.434515</td>\n      <td>2.456691</td>\n      <td>0.367709</td>\n    </tr>\n    <tr>\n      <th>510062</th>\n      <td>NaN</td>\n      <td>0.248052</td>\n      <td>0.009841</td>\n      <td>0.010724</td>\n      <td>-0.805532</td>\n      <td>-0.014599</td>\n      <td>1.021628</td>\n      <td>1.489092</td>\n      <td>-0.361747</td>\n      <td>-1.233647</td>\n      <td>...</td>\n      <td>-0.772674</td>\n      <td>0.130366</td>\n      <td>2.494628</td>\n      <td>0.868327</td>\n      <td>0.411586</td>\n      <td>-0.287139</td>\n      <td>1.632814</td>\n      <td>2.557848</td>\n      <td>-0.216548</td>\n      <td>0.534780</td>\n    </tr>\n    <tr>\n      <th>534815</th>\n      <td>-1.035620</td>\n      <td>0.587509</td>\n      <td>-1.709698</td>\n      <td>-1.040852</td>\n      <td>0.947988</td>\n      <td>0.586136</td>\n      <td>-1.364958</td>\n      <td>NaN</td>\n      <td>-0.242823</td>\n      <td>1.099015</td>\n      <td>...</td>\n      <td>-1.139737</td>\n      <td>-0.900421</td>\n      <td>0.544825</td>\n      <td>0.738696</td>\n      <td>-0.675178</td>\n      <td>-0.490468</td>\n      <td>-1.083962</td>\n      <td>2.272816</td>\n      <td>-0.535574</td>\n      <td>0.621225</td>\n    </tr>\n    <tr>\n      <th>342590</th>\n      <td>0.260022</td>\n      <td>1.857708</td>\n      <td>NaN</td>\n      <td>-0.050537</td>\n      <td>-0.253518</td>\n      <td>-0.591818</td>\n      <td>-0.134732</td>\n      <td>0.407089</td>\n      <td>0.123022</td>\n      <td>0.778944</td>\n      <td>...</td>\n      <td>-1.181412</td>\n      <td>2.432050</td>\n      <td>-1.053403</td>\n      <td>0.985205</td>\n      <td>-0.903371</td>\n      <td>1.016687</td>\n      <td>-3.691421</td>\n      <td>0.837269</td>\n      <td>3.431231</td>\n      <td>0.648106</td>\n    </tr>\n    <tr>\n      <th>559414</th>\n      <td>-0.070327</td>\n      <td>0.211908</td>\n      <td>-1.751384</td>\n      <td>-1.461679</td>\n      <td>-1.290441</td>\n      <td>1.525672</td>\n      <td>-0.437284</td>\n      <td>0.144728</td>\n      <td>0.700818</td>\n      <td>0.694507</td>\n      <td>...</td>\n      <td>-0.112494</td>\n      <td>-2.676754</td>\n      <td>-0.060217</td>\n      <td>-0.468202</td>\n      <td>0.383181</td>\n      <td>0.899809</td>\n      <td>NaN</td>\n      <td>3.984332</td>\n      <td>-0.377657</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>259178</th>\n      <td>1.218796</td>\n      <td>NaN</td>\n      <td>0.267737</td>\n      <td>0.774914</td>\n      <td>-1.568090</td>\n      <td>-0.727271</td>\n      <td>-0.050377</td>\n      <td>-0.014268</td>\n      <td>1.754509</td>\n      <td>-1.515554</td>\n      <td>...</td>\n      <td>-2.818447</td>\n      <td>-0.666565</td>\n      <td>1.312525</td>\n      <td>-0.076391</td>\n      <td>-0.493262</td>\n      <td>0.182865</td>\n      <td>3.726244</td>\n      <td>0.651348</td>\n      <td>-0.308762</td>\n      <td>1.018395</td>\n    </tr>\n    <tr>\n      <th>365838</th>\n      <td>0.741771</td>\n      <td>0.566133</td>\n      <td>-0.015954</td>\n      <td>-1.099916</td>\n      <td>0.742518</td>\n      <td>-1.109014</td>\n      <td>0.628161</td>\n      <td>0.216517</td>\n      <td>0.127800</td>\n      <td>0.163856</td>\n      <td>...</td>\n      <td>1.847194</td>\n      <td>-1.782025</td>\n      <td>1.049517</td>\n      <td>0.106738</td>\n      <td>-0.952896</td>\n      <td>0.327642</td>\n      <td>1.275427</td>\n      <td>2.628004</td>\n      <td>0.224034</td>\n      <td>0.503405</td>\n    </tr>\n    <tr>\n      <th>131932</th>\n      <td>-1.266722</td>\n      <td>0.024304</td>\n      <td>-1.112762</td>\n      <td>-0.068065</td>\n      <td>-0.397668</td>\n      <td>0.739804</td>\n      <td>0.623387</td>\n      <td>0.264382</td>\n      <td>-0.661810</td>\n      <td>-0.499827</td>\n      <td>...</td>\n      <td>1.892844</td>\n      <td>-1.560886</td>\n      <td>0.372720</td>\n      <td>-0.764522</td>\n      <td>0.614927</td>\n      <td>0.875461</td>\n      <td>-5.531109</td>\n      <td>6.277756</td>\n      <td>-2.384959</td>\n      <td>0.099292</td>\n    </tr>\n    <tr>\n      <th>671155</th>\n      <td>-0.575121</td>\n      <td>0.014076</td>\n      <td>-1.933780</td>\n      <td>0.863119</td>\n      <td>-1.222825</td>\n      <td>0.863869</td>\n      <td>-0.464296</td>\n      <td>1.049259</td>\n      <td>1.380140</td>\n      <td>-0.046534</td>\n      <td>...</td>\n      <td>0.249582</td>\n      <td>1.081619</td>\n      <td>-3.197704</td>\n      <td>0.666860</td>\n      <td>-0.705164</td>\n      <td>0.543630</td>\n      <td>-5.280212</td>\n      <td>-0.053185</td>\n      <td>-0.108882</td>\n      <td>-0.344734</td>\n    </tr>\n    <tr>\n      <th>121958</th>\n      <td>0.233272</td>\n      <td>0.503249</td>\n      <td>0.252610</td>\n      <td>-0.194540</td>\n      <td>2.045176</td>\n      <td>0.613187</td>\n      <td>0.294033</td>\n      <td>-0.566269</td>\n      <td>-1.870568</td>\n      <td>0.534392</td>\n      <td>...</td>\n      <td>4.169731</td>\n      <td>-1.394576</td>\n      <td>-1.150761</td>\n      <td>NaN</td>\n      <td>-1.660472</td>\n      <td>-0.930751</td>\n      <td>0.381797</td>\n      <td>0.669120</td>\n      <td>-0.079348</td>\n      <td>-0.149050</td>\n    </tr>\n  </tbody>\n</table>\n<p>900000 rows × 80 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"mask_train","metadata":{"execution":{"iopub.status.busy":"2022-06-06T07:20:45.811634Z","iopub.execute_input":"2022-06-06T07:20:45.811946Z","iopub.status.idle":"2022-06-06T07:20:45.877478Z","shell.execute_reply.started":"2022-06-06T07:20:45.811919Z","shell.execute_reply":"2022-06-06T07:20:45.876665Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"        F_1_0  F_1_1  F_1_2  F_1_3  F_1_4  F_1_5  F_1_6  F_1_7  F_1_8  F_1_9  \\\nrow_id                                                                         \n378046      0      0      0      1      0      0      0      0      0      0   \n510062      1      0      0      0      0      0      0      0      0      0   \n534815      0      0      0      0      0      0      0      1      0      0   \n342590      0      0      1      0      0      0      0      0      0      0   \n559414      0      0      0      0      0      0      0      0      0      0   \n...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n259178      0      1      0      0      0      0      0      0      0      0   \n365838      0      0      0      0      0      0      0      0      0      0   \n131932      0      0      0      0      0      0      0      0      0      0   \n671155      0      0      0      0      0      0      0      0      0      0   \n121958      0      0      0      0      0      0      0      0      0      0   \n\n        ...  F_4_5  F_4_6  F_4_7  F_4_8  F_4_9  F_4_10  F_4_11  F_4_12  \\\nrow_id  ...                                                              \n378046  ...      0      0      0      0      0       0       0       0   \n510062  ...      0      0      0      0      0       0       0       0   \n534815  ...      0      0      0      0      0       0       0       0   \n342590  ...      0      0      0      0      0       0       0       0   \n559414  ...      0      0      0      0      0       0       1       0   \n...     ...    ...    ...    ...    ...    ...     ...     ...     ...   \n259178  ...      0      0      0      0      0       0       0       0   \n365838  ...      0      0      0      0      0       0       0       0   \n131932  ...      0      0      0      0      0       0       0       0   \n671155  ...      0      0      0      0      0       0       0       0   \n121958  ...      0      0      0      1      0       0       0       0   \n\n        F_4_13  F_4_14  \nrow_id                  \n378046       0       0  \n510062       0       0  \n534815       0       0  \n342590       0       0  \n559414       0       1  \n...        ...     ...  \n259178       0       0  \n365838       0       0  \n131932       0       0  \n671155       0       0  \n121958       0       0  \n\n[900000 rows x 80 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>F_1_0</th>\n      <th>F_1_1</th>\n      <th>F_1_2</th>\n      <th>F_1_3</th>\n      <th>F_1_4</th>\n      <th>F_1_5</th>\n      <th>F_1_6</th>\n      <th>F_1_7</th>\n      <th>F_1_8</th>\n      <th>F_1_9</th>\n      <th>...</th>\n      <th>F_4_5</th>\n      <th>F_4_6</th>\n      <th>F_4_7</th>\n      <th>F_4_8</th>\n      <th>F_4_9</th>\n      <th>F_4_10</th>\n      <th>F_4_11</th>\n      <th>F_4_12</th>\n      <th>F_4_13</th>\n      <th>F_4_14</th>\n    </tr>\n    <tr>\n      <th>row_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>378046</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>510062</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>534815</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>342590</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>559414</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>259178</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>365838</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>131932</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>671155</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>121958</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>900000 rows × 80 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n","metadata":{"execution":{"iopub.status.busy":"2022-06-06T07:41:21.991053Z","iopub.execute_input":"2022-06-06T07:41:21.991863Z","iopub.status.idle":"2022-06-06T07:41:22.586144Z","shell.execute_reply.started":"2022-06-06T07:41:21.991813Z","shell.execute_reply":"2022-06-06T07:41:22.585290Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"def masked_rmse(y_true, y_pred, mask):\n    return K.sqrt(K.mean(K.square(y_pred - y_true))) * (1 - mask) \n\nclass MaskedLossEndpoint(keras.layers.Layer):\n    def __init__(self, name=None):\n        super().__init__(name=Name)\n        self.loss_fn = masked_rmse\n\n    def call(self, x_true, x_pred=None, mask=None):\n        if x_pred is not None:\n            # Compute the training-time loss value and add it\n            # to the layer using `self.add_loss()`.\n            loss = self.loss_fn(x_true, x_pred, mask)\n            self.add_loss(loss)\n            # Log the accuracy as a metric (we could log arbitrary metrics,\n            # including different metrics for training and inference.\n            self.add_metric(loss)\n        # Return the inference-time prediction tensor (for `.predict()`).\n        return x_pred","metadata":{"execution":{"iopub.status.busy":"2022-06-06T07:41:57.608661Z","iopub.execute_input":"2022-06-06T07:41:57.609706Z","iopub.status.idle":"2022-06-06T07:41:57.617947Z","shell.execute_reply.started":"2022-06-06T07:41:57.609652Z","shell.execute_reply":"2022-06-06T07:41:57.616930Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"NCOLS = x_train.shape[1]\nclass Autoencoder(keras.layers.Layer):\n    def __init__(self,name=None):\n        super().__init__(name=name)\n        self.endpoint = MaskedLossEndpoint()\n        \n        norm = keras.layers.Normalization()\n        norm.adapt(x_train.sample(10000))\n        \n        self.norm = norm\n        self.encoder = keras.Sequential([\n            keras.layers.Dense(1)\n        ])\n        self.decoder = keras.Sequential([\n            keras.layers.Dense(NCOLS)\n        ])\n    \n    def call(self, x_true, mask, training=True):\n        \n        \n    def train_step(self, data):\n        x_true, mask, x_pred = data\n\n        with tf.GradientTape() as tape:\n            x_enc = self.encoder(x_true, mask, training=True)  # Forward pass\n            loss = self.endpoint(x_true, x_pred, mask)\n            \n        # Compute gradients\n        trainable_vars = self.trainable_variables\n        gradients = tape.gradient(loss, trainable_vars)\n\n        # Update weights\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n\n        # Update the metrics.\n        # Metrics are configured in `compile()`.\n        self.compiled_metrics.update_state(y, y_pred, sample_weight=sample_weight)\n\n        # Return a dict mapping metric names to current value.\n        # Note that it will include the loss (tracked in self.metrics).\n        return {m.name: m.result() for m in self.metrics}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ninputs = {}\nmasks = {}\nnormed = {}\n\nfor (col,val),(_,mask) in tqdm(zip(x_train.iteritems(), mask_train.iteritems()), total=x_train.shape[1]):\n    inputs[col] = keras.Input((1,), name=col, dtype=val.dtype)\n    masks[col] =  keras.Input((1,), name=col+'_mask', dtype=mask.dtype)\n    norm = keras.layers.Normalization()\n    sample = val[mask!=1].sample(10000).values.reshape(-1,1)\n    norm.adapt(sample)\n    normed[col] = norm(inputs[col])","metadata":{"execution":{"iopub.status.busy":"2022-06-06T07:24:25.526839Z","iopub.execute_input":"2022-06-06T07:24:25.527236Z","iopub.status.idle":"2022-06-06T07:25:00.579789Z","shell.execute_reply.started":"2022-06-06T07:24:25.527202Z","shell.execute_reply":"2022-06-06T07:25:00.578693Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"100%|██████████| 80/80 [00:35<00:00,  2.28it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"preprocessing_model = keras.Model(inputs={'inputs':inputs, 'masks':masks}, \n                                  outputs={'normed':normed, 'masks':masks})\nsample = x_train.sample(50)\nsample = {\n    'inputs' : sample.to_dict('series'),\n    'mask': mask_train.loc[sample.index].to_dict('series')\n}\nout = preprocessing_model(sample)\ntf.nest.map_structure(lambda x: x.shape, out)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T07:27:29.943925Z","iopub.execute_input":"2022-06-06T07:27:29.944320Z","iopub.status.idle":"2022-06-06T07:27:30.042002Z","shell.execute_reply.started":"2022-06-06T07:27:29.944286Z","shell.execute_reply":"2022-06-06T07:27:30.040817Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"{'normed': {'F_1_0': TensorShape([1, 50]),\n  'F_1_1': TensorShape([1, 50]),\n  'F_1_2': TensorShape([1, 50]),\n  'F_1_3': TensorShape([1, 50]),\n  'F_1_4': TensorShape([1, 50]),\n  'F_1_5': TensorShape([1, 50]),\n  'F_1_6': TensorShape([1, 50]),\n  'F_1_7': TensorShape([1, 50]),\n  'F_1_8': TensorShape([1, 50]),\n  'F_1_9': TensorShape([1, 50]),\n  'F_1_10': TensorShape([1, 50]),\n  'F_1_11': TensorShape([1, 50]),\n  'F_1_12': TensorShape([1, 50]),\n  'F_1_13': TensorShape([1, 50]),\n  'F_1_14': TensorShape([1, 50]),\n  'F_2_0': TensorShape([1, 50]),\n  'F_2_1': TensorShape([1, 50]),\n  'F_2_2': TensorShape([1, 50]),\n  'F_2_3': TensorShape([1, 50]),\n  'F_2_4': TensorShape([1, 50]),\n  'F_2_5': TensorShape([1, 50]),\n  'F_2_6': TensorShape([1, 50]),\n  'F_2_7': TensorShape([1, 50]),\n  'F_2_8': TensorShape([1, 50]),\n  'F_2_9': TensorShape([1, 50]),\n  'F_2_10': TensorShape([1, 50]),\n  'F_2_11': TensorShape([1, 50]),\n  'F_2_12': TensorShape([1, 50]),\n  'F_2_13': TensorShape([1, 50]),\n  'F_2_14': TensorShape([1, 50]),\n  'F_2_15': TensorShape([1, 50]),\n  'F_2_16': TensorShape([1, 50]),\n  'F_2_17': TensorShape([1, 50]),\n  'F_2_18': TensorShape([1, 50]),\n  'F_2_19': TensorShape([1, 50]),\n  'F_2_20': TensorShape([1, 50]),\n  'F_2_21': TensorShape([1, 50]),\n  'F_2_22': TensorShape([1, 50]),\n  'F_2_23': TensorShape([1, 50]),\n  'F_2_24': TensorShape([1, 50]),\n  'F_3_0': TensorShape([1, 50]),\n  'F_3_1': TensorShape([1, 50]),\n  'F_3_2': TensorShape([1, 50]),\n  'F_3_3': TensorShape([1, 50]),\n  'F_3_4': TensorShape([1, 50]),\n  'F_3_5': TensorShape([1, 50]),\n  'F_3_6': TensorShape([1, 50]),\n  'F_3_7': TensorShape([1, 50]),\n  'F_3_8': TensorShape([1, 50]),\n  'F_3_9': TensorShape([1, 50]),\n  'F_3_10': TensorShape([1, 50]),\n  'F_3_11': TensorShape([1, 50]),\n  'F_3_12': TensorShape([1, 50]),\n  'F_3_13': TensorShape([1, 50]),\n  'F_3_14': TensorShape([1, 50]),\n  'F_3_15': TensorShape([1, 50]),\n  'F_3_16': TensorShape([1, 50]),\n  'F_3_17': TensorShape([1, 50]),\n  'F_3_18': TensorShape([1, 50]),\n  'F_3_19': TensorShape([1, 50]),\n  'F_3_20': TensorShape([1, 50]),\n  'F_3_21': TensorShape([1, 50]),\n  'F_3_22': TensorShape([1, 50]),\n  'F_3_23': TensorShape([1, 50]),\n  'F_3_24': TensorShape([1, 50]),\n  'F_4_0': TensorShape([1, 50]),\n  'F_4_1': TensorShape([1, 50]),\n  'F_4_2': TensorShape([1, 50]),\n  'F_4_3': TensorShape([1, 50]),\n  'F_4_4': TensorShape([1, 50]),\n  'F_4_5': TensorShape([1, 50]),\n  'F_4_6': TensorShape([1, 50]),\n  'F_4_7': TensorShape([1, 50]),\n  'F_4_8': TensorShape([1, 50]),\n  'F_4_9': TensorShape([1, 50]),\n  'F_4_10': TensorShape([1, 50]),\n  'F_4_11': TensorShape([1, 50]),\n  'F_4_12': TensorShape([1, 50]),\n  'F_4_13': TensorShape([1, 50]),\n  'F_4_14': TensorShape([1, 50])},\n 'masks': {'F_1_0': (50,),\n  'F_1_1': (50,),\n  'F_1_2': (50,),\n  'F_1_3': (50,),\n  'F_1_4': (50,),\n  'F_1_5': (50,),\n  'F_1_6': (50,),\n  'F_1_7': (50,),\n  'F_1_8': (50,),\n  'F_1_9': (50,),\n  'F_1_10': (50,),\n  'F_1_11': (50,),\n  'F_1_12': (50,),\n  'F_1_13': (50,),\n  'F_1_14': (50,),\n  'F_2_0': (50,),\n  'F_2_1': (50,),\n  'F_2_2': (50,),\n  'F_2_3': (50,),\n  'F_2_4': (50,),\n  'F_2_5': (50,),\n  'F_2_6': (50,),\n  'F_2_7': (50,),\n  'F_2_8': (50,),\n  'F_2_9': (50,),\n  'F_2_10': (50,),\n  'F_2_11': (50,),\n  'F_2_12': (50,),\n  'F_2_13': (50,),\n  'F_2_14': (50,),\n  'F_2_15': (50,),\n  'F_2_16': (50,),\n  'F_2_17': (50,),\n  'F_2_18': (50,),\n  'F_2_19': (50,),\n  'F_2_20': (50,),\n  'F_2_21': (50,),\n  'F_2_22': (50,),\n  'F_2_23': (50,),\n  'F_2_24': (50,),\n  'F_3_0': (50,),\n  'F_3_1': (50,),\n  'F_3_2': (50,),\n  'F_3_3': (50,),\n  'F_3_4': (50,),\n  'F_3_5': (50,),\n  'F_3_6': (50,),\n  'F_3_7': (50,),\n  'F_3_8': (50,),\n  'F_3_9': (50,),\n  'F_3_10': (50,),\n  'F_3_11': (50,),\n  'F_3_12': (50,),\n  'F_3_13': (50,),\n  'F_3_14': (50,),\n  'F_3_15': (50,),\n  'F_3_16': (50,),\n  'F_3_17': (50,),\n  'F_3_18': (50,),\n  'F_3_19': (50,),\n  'F_3_20': (50,),\n  'F_3_21': (50,),\n  'F_3_22': (50,),\n  'F_3_23': (50,),\n  'F_3_24': (50,),\n  'F_4_0': (50,),\n  'F_4_1': (50,),\n  'F_4_2': (50,),\n  'F_4_3': (50,),\n  'F_4_4': (50,),\n  'F_4_5': (50,),\n  'F_4_6': (50,),\n  'F_4_7': (50,),\n  'F_4_8': (50,),\n  'F_4_9': (50,),\n  'F_4_10': (50,),\n  'F_4_11': (50,),\n  'F_4_12': (50,),\n  'F_4_13': (50,),\n  'F_4_14': (50,)}}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}